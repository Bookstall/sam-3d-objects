{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Copyright (c) Meta Platforms, Inc. and affiliates."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "\n",
                "# import sam-3d-objects code\n",
                "sys.path.append(\"/data/machine_learning/cpx/sam-3d-objects\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "环境变量设置验证\n",
                        "============================================================\n",
                        "✓ ninja found at: /data/machine_learning/cpx/sam-3d-objects/.venv/bin/ninja\n",
                        "✓ nvcc found at: /data/CUDA/cuda-12.4/bin/nvcc\n",
                        "✓ torch.utils.cpp_extension.is_ninja_available(): True\n",
                        "✓ torch.utils.cpp_extension.verify_ninja_availability() passed\n",
                        "============================================================\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import shutil\n",
                "\n",
                "# ============================================\n",
                "# 重要：必须在导入任何使用 torch cpp_extension 的模块之前设置环境变量\n",
                "# ============================================\n",
                "\n",
                "# 正确设置环境变量 PATH（需要先获取当前 PATH，然后拼接）\n",
                "current_path = os.environ.get(\"PATH\", \"\")\n",
                "cuda_bin = \"/data/CUDA/cuda-12.4/bin\"\n",
                "venv_bin = \"/data/machine_learning/cpx/sam-3d-objects/.venv/bin\"\n",
                "\n",
                "# 将 CUDA bin 和 venv bin 添加到 PATH（确保 ninja 可执行文件能被找到）\n",
                "# 注意：将 venv_bin 放在最前面，确保优先使用虚拟环境中的工具\n",
                "new_path = f\"{venv_bin}:{cuda_bin}:{current_path}\"\n",
                "os.environ[\"PATH\"] = new_path\n",
                "\n",
                "# 设置 CUDA 相关环境变量\n",
                "os.environ[\"TORCH_CUDA_ARCH_LIST\"] = \"8.0\"\n",
                "os.environ[\"CUDA_HOME\"] = \"/data/CUDA/cuda-12.4\"\n",
                "os.environ[\"MAX_JOBS\"] = \"8\"\n",
                "\n",
                "# 验证关键工具是否在 PATH 中\n",
                "print(\"=\" * 60)\n",
                "print(\"环境变量设置验证\")\n",
                "print(\"=\" * 60)\n",
                "ninja_path = shutil.which(\"ninja\")\n",
                "nvcc_path = shutil.which(\"nvcc\")\n",
                "print(f\"✓ ninja found at: {ninja_path}\")\n",
                "print(f\"✓ nvcc found at: {nvcc_path}\")\n",
                "if not ninja_path:\n",
                "    print(\"⚠ WARNING: ninja not found in PATH! This may cause gsplat compilation to fail.\")\n",
                "if not nvcc_path:\n",
                "    print(\"⚠ WARNING: nvcc not found in PATH! This may cause CUDA compilation to fail.\")\n",
                "\n",
                "# 验证 torch 是否能检测到 ninja\n",
                "# 注意：如果 torch 已经在之前的 cell 中被导入，可能需要重启内核\n",
                "try:\n",
                "    import torch.utils.cpp_extension\n",
                "    # 强制重新检查 ninja 可用性\n",
                "    is_available = torch.utils.cpp_extension.is_ninja_available()\n",
                "    print(f\"✓ torch.utils.cpp_extension.is_ninja_available(): {is_available}\")\n",
                "    if not is_available:\n",
                "        print(\"⚠ WARNING: torch cannot detect ninja!\")\n",
                "        print(\"⚠ 如果 torch 在设置 PATH 之前已被导入，请重启 Jupyter 内核后重新运行。\")\n",
                "    else:\n",
                "        # 尝试调用 verify_ninja_availability 来确保它能正常工作\n",
                "        try:\n",
                "            torch.utils.cpp_extension.verify_ninja_availability()\n",
                "            print(\"✓ torch.utils.cpp_extension.verify_ninja_availability() passed\")\n",
                "        except RuntimeError as e:\n",
                "            print(f\"✗ torch.utils.cpp_extension.verify_ninja_availability() failed: {e}\")\n",
                "            print(\"⚠ 请重启 Jupyter 内核后重新运行。\")\n",
                "except ImportError:\n",
                "    print(\"ℹ torch 尚未导入，这是正常的。环境变量将在导入时生效。\")\n",
                "except Exception as e:\n",
                "    print(f\"⚠ WARNING: Could not verify ninja availability: {e}\")\n",
                "\n",
                "print(\"=\" * 60)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Imports and Model Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32m2026-01-16 11:56:44.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36mset_attention_backend\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mGPU name is NVIDIA A800 80GB PCIe\u001b[0m\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
                        "[Open3D INFO] WebRTC GUI backend enabled.\n",
                        "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32m2026-01-16 11:56:45.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.tdfy_dit.modules.sparse\u001b[0m:\u001b[36m__from_env\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1m[SPARSE] Backend: spconv, Attention: flash_attn\u001b[0m\n",
                        "\u001b[32m2026-01-16 11:56:49.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.tdfy_dit.modules.attention\u001b[0m:\u001b[36m__from_env\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1m[ATTENTION] Using backend: flash_attn\u001b[0m\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[SPARSE][CONV] spconv algo: auto\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32m2026-01-16 11:56:50.564\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msam3d_objects.data.dataset.tdfy.preprocessor\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[33m\u001b[1mNo rgb pointmap normalizer provided, using scale + shift \u001b[0m\n",
                        "\u001b[32m2026-01-16 11:56:50.565\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msam3d_objects.data.dataset.tdfy.preprocessor\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[33m\u001b[1mNo rgb pointmap normalizer provided, using scale + shift \u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import uuid\n",
                "import imageio\n",
                "import numpy as np\n",
                "from IPython.display import Image as ImageDisplay\n",
                "\n",
                "from inference import Inference, ready_gaussian_for_video_rendering, load_image, load_masks, display_image, make_scene, render_video, interactive_visualizer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "config_path = \"/data/models/LLM-models-file/sam-3d-objects/checkpoints/pipeline.yaml\"\n",
                "inference = Inference(config_path, compile=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load input image to lift to 3D (multiple objects)\n",
                "\n",
                "加载输入图像和 Mask，以便提升为 3D（多个对象）"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "IMAGE_PATH = \"./images/shutterstock_stylish_kidsroom_1640806567/image.png\"\n",
                "IMAGE_NAME = os.path.basename(os.path.dirname(IMAGE_PATH))\n",
                "\n",
                "image = load_image(IMAGE_PATH)\n",
                "masks = load_masks(os.path.dirname(IMAGE_PATH), extension=\".png\")\n",
                "display_image(image, masks)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Generate Gaussian Splats\n",
                "\n",
                "生成高斯溅射（一种 3D 渲染方法）"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "outputs = [inference(image, mask, seed=42) for mask in masks]\n",
                "\n",
                "# for index, output in enumerate(outputs):\n",
                "#     # 导出高斯溅射\n",
                "#     output[\"gs\"].save_ply(f\"./gaussians/single/{IMAGE_NAME}_{index}.ply\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"length of outputs: {len(outputs)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Visualize Gaussian Splat of the Scene\n",
                "### a. Animated Gif"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scene_gs = make_scene(*outputs)\n",
                "# export posed gaussian splatting (as point cloud)\n",
                "scene_gs.save_ply(f\"./gaussians/{IMAGE_NAME}_posed.ply\")\n",
                "\n",
                "scene_gs = ready_gaussian_for_video_rendering(scene_gs)\n",
                "# export gaussian splatting (as point cloud)\n",
                "scene_gs.save_ply(f\"./gaussians/multi/{IMAGE_NAME}.ply\")\n",
                "\n",
                "video = render_video(\n",
                "    scene_gs,\n",
                "    r=1,\n",
                "    fov=60,\n",
                "    resolution=512,\n",
                ")[\"color\"]\n",
                "\n",
                "# save video as gif\n",
                "imageio.mimsave(\n",
                "    os.path.join(f\"./gaussians/multi/{IMAGE_NAME}.gif\"),\n",
                "    video,\n",
                "    format=\"GIF\",\n",
                "    duration=1000 / 30,  # default assuming 30fps from the input MP4\n",
                "    loop=0,  # 0 means loop indefinitely\n",
                ")\n",
                "\n",
                "# notebook display\n",
                "ImageDisplay(url=f\"gaussians/multi/{IMAGE_NAME}.gif?cache_invalidator={uuid.uuid4()}\",)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### b. Interactive Visualizer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# might take a while to load (black screen)\n",
                "interactive_visualizer(f\"./gaussians/multi/{IMAGE_NAME}.ply\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
